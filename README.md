# PageRank Web Crawler (PyQt5)

Комп’ютерний проєкт з дискретної математики, який поєднує:

* обхід веб-сторінок (web crawler),
* побудову графа посилань,
* обчислення **PageRank** для цього графа,
* зручний **графічний інтерфейс** на PyQt5.

Кожна вершина графа відповідає одній веб-сторінці, а ребро `A -> B` означає, що сторінка A містить посилання на сторінку B.
Мета — показати, які сторінки в цьому «локальному шматочку Інтернету» є найважливішими за алгоритмом PageRank.

---

## Можливості

* Обхід веб-сторінок, починаючи з вказаного користувачем URL.
* Обмеження:

  * максимальної глибини обходу,
  * максимальної кількості лінків, що беруться з однієї сторінки.
* Автоматичне формування текстового файлу з ребрами графа у форматі:

  ```text
  source_url -> destination_url
  ```
* Побудова внутрішньої структури графа:

  * вхідні та вихідні посилання для кожної вершини,
  * множина всіх вершин (сайтів).
* Обчислення PageRank із:

  * коефіцієнтом згасання (*damping factor*) `d = 0.85`,
  * врахуванням «висячих» вершин (без вихідних посилань),
  * ітерацією до збіжності (похибка < `1e-6`).
* Вивід **топ-10 сторінок за PageRank** у вікні застосунку.
* Логування процесу обходу в реальному часі прямо в інтерфейсі.

---

## Технології

* **Python 3.10+**
* **PyQt5** — графічний інтерфейс (вікно, форми, кнопки, лог).
* **urllib** — завантаження HTML та робота з URL.
* **re** — пошук посилань у HTML через регулярні вирази.
* Стандартна бібліотека Python (файли, обробка рядків тощо).

---

## Алгоритм PageRank

Для кожної вершини (сторінки) `i` PageRank обчислюється за формулою:

$$
PR(i) = \frac{1 - d}{N} + d \left( \sum_{j \in In(i)} \frac{PR(j)}{L(j)} + \frac{S}{N} \right)
$$

де:

* `d` — коефіцієнт згасання (у проєкті `0.85`);
* `N` — кількість вершин у графі;
* `In(i)` — множина вершин, які посилаються на `i`;
* `L(j)` — кількість вихідних посилань з вершини `j`;
* `S` — сумарний PageRank усіх вершин без вихідних лінків (так звані *висячі вершини*).

Алгоритм:

1. Ініціалізуємо всі вершини однаковим значенням `1 / N`.
2. На кожній ітерації перераховуємо `PR(i)` для всіх вершин.
3. Процес повторюється, поки зміни для всіх вершин не стануть меншими за `1e-6`.
4. У фіналі значення сортуються за спаданням — це і є ранжування сторінок.

---

## Як працює crawler

1. Користувач вводить:

   * стартовий **URL**,
   * **максимальну глибину** пошуку,
   * **максимальну кількість лінків з однієї сторінки**.
2. Програма завантажує HTML стартової сторінки.
3. Шукає всі збіги `href="..."` за допомогою регулярного виразу.
4. Для кожного посилання:

   * перетворює його на абсолютний URL (`urljoin`),
   * прибирає «якорі» (`urldefrag`),
   * відкидає технічні/непотрібні лінки:

     * `mailto:`, `javascript:`,
     * файли `.css`, `.js`, `.ico`, `.svg`, зображення тощо.
5. Кожен перехід записується в файл у форматі:

   ```text
   current_url -> found_url
   ```
6. Якщо дозволяє глибина — crawler переходить далі за знайденими посиланнями.
7. Кількість посилань, які беруться з однієї сторінки, обмежується параметром `max_links_per_page`.

Результат роботи crawler’а — файл з ребрами графа, на основі якого вже рахується PageRank.

---

## Формат вхідних/вихідних даних

### Вихідний файл з графом (наприклад, `menu.dot`)

```text
https://site-a.com -> https://site-b.com
https://site-a.com -> https://site-c.com
https://site-b.com -> https://site-c.com
https://site-d.com -> https://site-a.com
```

Файл використовується внутрішньо функціями:

* `read_file` — зчитує всі рядки,
* `create_dictionaries` — будуються:

  * `vertical_out` — для кожної сторінки: куди вона посилається,
  * `vertical_in` — для кожної сторінки: хто посилається на неї,
  * `page_rank` — початкові значення PR,
  * `vertexes` — множина всіх сторінок.

---

## Вимоги

* Python 3.10 або новіший
* Встановлений пакет **PyQt5**

Установка бібліотек (мінімально необхідне):

```bash
pip install PyQt5
```

---

## Запуск

1. Клонувати репозиторій:

```bash
git clone https://github.com/your-username/pagerank-web-crawler.git
cd pagerank-web-crawler
```

2. (Опційно) створити віртуальне середовище:

```bash
python -m venv venv
source venv/bin/activate  # Linux / macOS
venv\Scripts\activate     # Windows
```

3. Встановити залежності:

```bash
pip install PyQt5
```

4. Запустити застосунок:

```bash
python ready_project.py
```

---

## Використання

1. **URL для початку**
   Введіть стартову сторінку, наприклад:

   ```text
   https://example.com
   ```

2. **Максимальна глибина пошуку**

   * `0` — тільки стартова сторінка;
   * `1` — стартова + всі сторінки, на які вона посилається;
   * `2` — плюс сторінки, на які посилаються ті, що знайдені на попередньому кроці; і т.д.

3. **Максимальна кількість лінків з однієї сторінки**
   Обмежує, скільки посилань буде взято з кожної сторінки, навіть якщо в HTML їх більше.
   Це дозволяє не «роздувати» граф занадто сильно та не перевантажувати ні програму, ні сайти.

4. Натисніть кнопку **«Запустити пошук та PageRank»**.

5. У текстовому полі знизу ви побачите:

   * перебіг обходу,
   * повідомлення про завершення побудови графа,
   * **топ-10 сторінок за значенням PageRank**, наприклад:

     ```text
     === Топ-10 сторінок за PageRank ===
     0.123456  https://example.com
     0.098765  https://example.com/about
     ...
     ```
